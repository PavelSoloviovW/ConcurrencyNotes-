Паралелизм - паралельное выполнение задач, может быть достигнуто тремя способами

### Способы достижения паралелизма
* каждой задаче переодически выделяется квант процессорного времени, после текущие состояния задачи сохраняется в контексте, далее происходит смена контекста, и работает другая задача. Смена контеста тянет накладные расходы.
* задачи выполняются на разных ядрах одновременно, возможен если доступен аппаратный паралелизм (железо способно выполнять более одной задачи в один момент времени)
* совмещяется вариант 1 и 2

### Cпособы организации паралельных программ
1. Многопроцессорность:
	- **Преимущества:**\
		Изоляция: Каждый процесс имеет свое собственное адресное пространство, что обеспечивает высокую изоляцию между процессами.\
		Надежность: Если один процесс выходит из строя, это не влияет на другие процессы.
	- **Недостатки:**\
    Затраты на коммуникацию: Коммуникация между процессами требует дополнительных усилий и ресурсов.\
    Задержки: Из-за необходимости использования механизмов межпроцессорной связи могут возникать задержки.
2. Многопоточность:
	- **Преимущества:**\
		Эффективное использование ресурсов: Потоки в пределах одного процесса могут эффективно использовать общие ресурсы.\
		Быстрое взаимодействие: Потоки могут обмениваться данными более эффективно, чем процессы.
	- **Недостатки:**\
		Работа с общими данными: Необходимость синхронизации при работе с общими данными может вызывать проблемы, такие как гонки данных.\
		Неустойчивость: Если один поток вызывает ошибку, это может повлиять на все приложение.
		
### Причины применения паралелизма:

1. Разделение обязанностей:
	- **Описание:** Параллелизм позволяет разделить сложные задачи на более мелкие подзадачи, которые могут быть выполнены независимо друг от друга.
	- **Пример:** Разделение обработки данных на этапы, где каждый этап выполняется параллельно./UI потоки, позволяют не замораживать интерфейс, при выполнении работы.
2. Повышение производительности:
    - **Описание:** Использование параллелизма может значительно увеличить общую производительность системы, позволяя одновременно выполнять несколько задач или выполнять задачи паралельно над разными данными..
    - **Пример:** Распределение вычислений между несколькими ядрами процессора для более быстрого выполнения длительных задач.
	
### когда паралелизм вреден:
1. Зависимости между задачами: (трудно делимая задача, изза данных)
	- **Описание:** Если задачи имеют сильные зависимости друг от друга и требуют частого обмена данными, параллельное выполнение может столкнуться с большими накладными расходами на синхронизацию и обмен данными.
	- **Пример:** Алгоритм, где результат одной задачи является входными данными для следующей.
2. Небольшие вычислительные задачи: (цена на создание и уничтожения потока выше чем выигрыш от использования)
	- **Описание:** В случае небольших задач или задач, которые не требуют значительного вычислительного времени, накладные расходы на управление параллелизмом могут превысить выигрыш от параллельного выполнения.
	- **Пример:** Простые задачи, которые могут быть быстро выполнены на одном ядре процессора.
3. Ограниченные ресурсы: (большое количество паралельных задач, малый квант времени, регулярное потоковое голодание)
	- **Описание:** Если ресурсы, такие как память или процессорное время, ограничены, параллельные задачи могут конкурировать за эти ресурсы, что может привести к ухудшению производительности.
	- **Пример:** Множество параллельных задач, каждая из которых требует большой объем оперативной памяти.
4. Сложность управления параллелизмом: (сложно делимые задачи)
	- **Описание:** Некоторые задачи могут быть сложными для разделения на параллельные подзадачи или требовать сложной синхронизации, что усложняет управление параллелизмом.
	- **Пример:** Алгоритмы с большим числом взаимозависимых шагов.
5. Низкая загрузка процессора: (траты времени на то что не потребуется)
	- **Описание:** При низкой загрузке процессора или малом количестве данных для обработки в параллельных потоках создание и управление этими потоками может быть избыточным и затратным.
	- **Пример:** Простые задачи на маломасштабных системах.