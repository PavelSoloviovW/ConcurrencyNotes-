## Способы разделения работы между потоками
### Разделение по данным
1. **Распределение последовательных блоков данных:**
   - **Описание:** В этом методе данные разбиваются на последовательные блоки, и каждый поток выполняет одну и ту же операцию на своем блоке данных. Результаты обычно объединяются на стадии редукции, где получается окончательный результат.
   - **Применение:** Этот метод эффективен, когда данные можно заранее разделить на обрабатываемые части, и каждая часть может быть обработана независимо от других.
   - **Пример:** Умножение матриц — каждый поток может вычислять произведение своей подматрицы, и затем результаты объединяются.
2. **Рекурсивное распределение данных:**
   - **Описание:** В данном случае каждый поток выполняет одну и ту же операцию, но данные разбиваются в процессе обработки. Этот метод применяется, когда данные не могут быть заранее разделены, и требуется рекурсивное деление данных для параллельной обработки.
   - **Применение:** Эффективен, когда данные не могут быть разделены заранее, и процесс обработки требует динамического разбиения данных. Необходимо учесть потенциальное разрастание количества потоков.
   - **Пример:** Быстрая сортировка (quick sort) — каждый поток может сортировать свой блок данных, а затем объединять результаты.

### Распределение последовательности задач	
1. **Последовательное распределение задач (конвейер):**
В конвейерной обработке данные разделяются на последовательность этапов обработки, и каждый этап обрабатывает данные последовательно. Каждый этап может быть выполнен параллельно, но передача данных между этапами происходит последовательно. Таким образом, данные проходят через каждый этап в последовательном порядке, но на каждом этапе могут обрабатываться разные части данных параллельно.
	- преймущества:
		- можно тонко настроить производительность отдельных этапов конвеера. На сложный участок кинуть много потоков а на простой мало.
		- не требует распределения данных до начала работы, одним из этапов может как раз быть распределение данных
		- позволяет выдать непрерывный поток обработаных данных
		- можно переиспользовать части конвеера для других данных.
		- элементы можно обрабатывать при помощи разных этапов конвеера, пропуская или меняя тех процес при определенных условиях (фактически у тебя машина конвееров).
	- недостатки:
		- Более сложная инфраструктура: между любыми двумя слоями конвеера нужна будет очередь для передачи данных между конвеерами.
		- Может ухудшится время обработки одного куска по сравнению с паралельным выполнением изза накладных расходов.
2. **Параллельное распределение задач:**
В параллельном распределении данных каждая задача или блок данных обрабатывается независимо друг от друга параллельно. Различные блоки данных или задачи могут быть обработаны одновременно разными потоками или процессами.
	- преймущества:
		- Более простая реализация.
		- Нет дополнительных накладных расходов.
	- недостатки:
		- монолитная обработка, мы не сможем переконфигурировать этапы обработки для других данных.

### Распределение потоков по типам задач
Распределение потоков по типам задач — это стратегия, при которой различные потоки обрабатывают разные типы задач в системе. Каждый тип задач может быть оптимизирован и обработан специфичным образом. Это позволяет эффективно использовать ресурсы системы и повысить производительность. Вот некоторые общие типы задач и возможные способы распределения потоков:
1. **Вычислительные задачи:**
   - *Описание:* Задачи, требующие интенсивных вычислений.
   - *Распределение потоков:* Множество потоков, каждый из которых обрабатывает свой участок данных, например, в параллельных вычислениях.
2. **Задачи ввода-вывода (I/O):**
   - *Описание:* Задачи, связанные с чтением/записью данных, взаимодействием с внешними ресурсами.
   - *Распределение потоков:* Асинхронные потоки или потоки, управляемые событиями, для эффективной работы с вводом-выводом.
3. **Задачи обработки данных в реальном времени:**
   - *Описание:* Задачи, требующие мгновенной обработки и ответа.
   - *Распределение потоков:* Потоки с приоритетом для обработки данных в режиме реального времени.
4. **Параллельные задачи обработки событий:**
   - *Описание:* Задачи, связанные с обработкой асинхронных событий.
   - *Распределение потоков:* Потоки, обрабатывающие события, с использованием механизмов, таких как цикл событий.
   
## Факторы влияющие на производительность паралельного кода
1. **Количество потоков.** - на основе его подсчитуется количество потоков которое может запустить наш процес, не просадив общию производительность.
2. **Количество активных потоков** - ситуация при которой смена контекста забирает существенную часть производительности называется (oversubscription).
соблюдение оптимального соотношение количества хардверных потоков и количества активных потоков можно контролировать при помощи hardware_concurrency, не создовая слишком много потоков, или делегировать это системе при помощи std::async.
3. **Конкуренция за данные и перебрасывание кэша** - при обращении и изменении одних и тех же данных из разных потоков физического процессора. данные должны будут быть подтянуты в кеш ядра, если он находился в кеше другого ядра, то данные будут от туда извлечены, в результате чего мы можем замедлять всю работу алгоритма гоняя данные между разными кешами (cache ping-pong). Касается мютексов (так как операция прочитать и изменить) и других разделяемых данных. Количество потоков ухудшит прблему, так как участят случаи переброски кеша.
4. **Ложное разделение** - часный случай перебрасывания кеша, ячейки памяти находящиеся рядом (элементы массива допустим) поподают в одну строку кеша, и перебрасываются между кешами вместе, когда тому или иному ядру понадобится часть строки кеша, при этом вторая часть ему не нужна. (не брать элементы близкие друг другу вместе, иногда косается мемберов класса)

## Проэктирование структур данных
1. Распределение данных - манипулируя распределением данных в различных потоках, которые необходимо будет считать, мы можем добится увелечения производительности, так как мы не будем в кеш линии подгружать данные которые нам не нужны, и при этом сможем делать подгрузку реже подгружая большее количество данных нужных нам, и избегая ложного разделения данных. (пример, при подсчете перемножения матриц, мне прийдется существенно меньше вычитать элементов при разделении по приблеженным к квадрату плиткам выходной матрицы а не по строкам или столбцам)\
рекомендации:
	- Попытатся выбрать рспределения данных так чтоб соседние данные обрабатывались одним потокам (они попадут в одну кеш линию)
	- Минимизировать обем данных с которыми работает поток
	- данные к которым обращяются разные потоки находятся далеко друг от друга
	- так же касается структур, но не всегда, требует проверки конкретного случая, нужно отделить данные для проверки фейковой памятью
2. безопасность относительно исключений. Для любой структуры это очень важно даже при однопотоке. Итоговую версию нужно продумывать на безопасность по эксепшенам.\
При необходимости исключения можно вернуть вызывающиму коду при помощи специальных сущьностей.
3. **Масштабируемость (Scalability):**
Масштабируемость в контексте параллельных вычислений означает способность системы эффективно увеличивать свою производительность при увеличении количества ресурсов (чаще всего потоков, процессоров, узлов). Если система масштабируется, увеличение вычислительных ресурсов приводит к пропорциональному или близкому к пропорциональному увеличению производительности.
**Закон Амдала (Amdahl's Law):**
Закон Амдала формулирует ограничения параллельного ускорения, определяя, какой выигрыш в производительности можно получить от внедрения параллелизма в программу. Закон Амдала утверждает, что ускорение всей программы ограничивается долей последовательной части кода. Если доля последовательной части равна \(S\), а доля параллельной части \(P\), то ускорение \(A\) вычисляется по формуле:
\[A = \frac{1}{S + \frac{P}{N}}\]
где:
- \(S\) - доля последовательной части.
- \(P\) - доля параллельной части.
- \(N\) - количество процессоров (или потоков).
Из закона следует, что даже при бесконечном увеличении числа процессоров, ускорение будет ограничено долей последовательной части. Таким образом, для повышения эффективности параллельной программы необходимо уменьшать долю последовательной части (\(S\)) и максимизировать долю параллельной части (\(P\)).
4. **Сокрытие латентности**
Сокрытие латентности в многопоточных приложениях относится к методам уменьшения влияния временных задержек (латентности) на производительность. Латентность может возникнуть из различных источников, таких как ожидание ввода-вывода, доступ к данным из памяти, сетевые задержки и другие операции, которые могут занять значительное время.
5. **повышение быстроты реакции за счет распаралеливание** 
используй Распределение потоков по типам задач для обработки событий в UI.